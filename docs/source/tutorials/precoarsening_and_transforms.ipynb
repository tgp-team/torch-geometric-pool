{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81cb913",
   "metadata": {},
   "source": [
    "# Precoarsening and transforms\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tgp-team/torch-geometric-pool/blob/main/docs/source/tutorials/precoarsening_and_transforms.ipynb)\n",
    "\n",
    "Some pooling operators such as [`NDPPooling`](https://torch-geometric-pool.readthedocs.io/en/latest/api/poolers.html#tgp.poolers.NDPPooling), [`GraclusPooling`](https://torch-geometric-pool.readthedocs.io/en/latest/api/poolers.html#tgp.poolers.GraclusPooling), [`NMFPooling`](https://torch-geometric-pool.readthedocs.io/en/latest/api/poolers.html#tgp.poolers.NMFPooling) (and some configurations of [`KMISPooling`](https://torch-geometric-pool.readthedocs.io/en/latest/api/poolers.html#tgp.poolers.KMISPooling) and [`LaPooling`](https://torch-geometric-pool.readthedocs.io/en/latest/api/poolers.html#tgp.poolers.LaPooling)), compute the $\\texttt{SEL}$ only based on the topology of the adacency matrix. \n",
    "As opposed to the node features, which are modified by each layer of the GNN and evolve during training, the adjacency matrix is and remains fixed. \n",
    "Therefore, the $\\texttt{SEL}$ and the $\\texttt{CON}$ operations of these poolers is always the same and can be **precomputed** bofeore starting to train the GNN.\n",
    "This, allows us to save a lot of time during training because the only operation that we need to compute is the $\\texttt{RED}$ to compute the features of the supernodes.\n",
    "\n",
    "Let's start by loading some data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3cab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "if 'google.colab' in sys.modules:\n",
    "    import os\n",
    "    os.environ[\"TORCH\"] = torch.__version__\n",
    "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "    !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "    !pip install -q torch_geometric_pool[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root=\"/tmp/MUTAG\", name=\"MUTAG\", force_reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de593e",
   "metadata": {},
   "source": [
    "Let's now take the first graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376139b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4f0b0",
   "metadata": {},
   "source": [
    "Let's consider [`NDPPooling`](https://torch-geometric-pool.readthedocs.io/en/latest/api/poolers.html#tgp.poolers.NDPPooling): its $\\texttt{SEL}$ operation only looks at the graph connectivity. \n",
    "This means that we can compute the [`SelectOutput`](https://torch-geometric-pool.readthedocs.io/en/latest/api/select.html#tgp.select.SelectOutput) without having to pass the node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d002cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgp.connect import KronConnect\n",
    "from tgp.select import NDPSelect\n",
    "\n",
    "selector = NDPSelect()\n",
    "connector = KronConnect()\n",
    "\n",
    "# Compute pooled graph\n",
    "so = selector(data.edge_index)\n",
    "print(so)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b330327b",
   "metadata": {},
   "source": [
    "This also means that we can compute the coarsened graph connectivity witht the $\\texttt{CON}$ operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2cd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_pool = connector(data.edge_index, so)\n",
    "print(edge_index_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e40ce",
   "metadata": {},
   "source": [
    "```{note}\n",
    "[`NDPPooling`](https://torch-geometric-pool.readthedocs.io/en/latest/api/poolers.html#tgp.poolers.NDPPooling) uses the Kron reduction implemented by [`KronConnect`](https://torch-geometric-pool.readthedocs.io/en/latest/api/connect.html#tgp.connect.KronConnect) to compute the $\\texttt{connect}$ operation. However, once the [`SelectOutput`](https://torch-geometric-pool.readthedocs.io/en/latest/api/select.html#tgp.select.SelectOutput) is computed other $\\texttt{CON}$ opertions, e.g., [`SparseConnect`](https://torch-geometric-pool.readthedocs.io/en/latest/api/connect.html#tgp.connect.SparseConnect), can be used.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe767c1",
   "metadata": {},
   "source": [
    "At this point, we can apply the $\\texttt{SEL}$ and the $\\texttt{CON}$ operation one more time on the pooled graph. \n",
    "This is useful if we want to use a GNN architecture that applies pooling multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2 = selector(edge_index_pool[0], edge_index_pool[1])\n",
    "print(so2)\n",
    "\n",
    "edge_index_pool2 = connector(edge_index_pool[0], so2, edge_index_pool[1])\n",
    "print(edge_index_pool2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a531b",
   "metadata": {},
   "source": [
    "We can repeat the procedure iteratively for all the pooling levels that we want to have in our GNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7997da57",
   "metadata": {},
   "source": [
    "## The Precoarsening transform\n",
    "\n",
    "Precomputing pooling allows us to save a lot of time because we only need to do it once before starting to train our GNN.\n",
    "However, for each sample in our dataset we end up having an instance of [`SelectOutput`](https://torch-geometric-pool.readthedocs.io/en/latest/api/select.html#tgp.select.SelectOutput) and a pooled connectivity for each pooling level. \n",
    "Handling all of them during training, while keeping the correct association between data structures when we shuffle the data, is cumbersome.\n",
    "\n",
    "<img src=\"../_static/img/tgp-logo.svg\" width=\"20px\" align=\"center\" style=\"display: inline-block; height: 1.3em; width: unset; vertical-align: text-top;\"/> tgp provides a couple of tools to handle precomputed pooled graphs efficiently. \n",
    "The first is the [`PreCoarsening`](https://torch-geometric-pool.readthedocs.io/en/latest/api/data/transforms.html#tgp.data.transforms.PreCoarsening) transform, which can be directly applied to the dataset like all the other [PyG `transforms`](https://pytorch-geometric.readthedocs.io/en/2.5.2/modules/transforms.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e5eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgp.poolers import NDPPooling\n",
    "from tgp.data import PreCoarsening\n",
    "\n",
    "dataset = TUDataset(\n",
    "    root=\"/tmp/MUTAG\",\n",
    "    name=\"MUTAG\",\n",
    "    pre_transform=PreCoarsening(\n",
    "        poolers=[NDPPooling(), NDPPooling()]\n",
    "    ),\n",
    "    force_reload=True,\n",
    ")\n",
    "\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d22bd",
   "metadata": {},
   "source": [
    "Once again we look at the first element of the dataset and this time we see that, compared to the standard [`Data`](https://pytorch-geometric.readthedocs.io/en/stable/generated/torch_geometric.data.Data.html) structure, there is an additional field, `pooled_data`, which is a list of length `recursive_depth`.\n",
    "The elements in the list are the hierarchy of pooled graphs computed with the `selector` and `connector` that we defined in the [`PreCoarsening`](https://torch-geometric-pool.readthedocs.io/en/latest/api/data/transforms.html#tgp.data.transforms.PreCoarsening) transform. \n",
    "\n",
    "Each pooled graph is a [`Data`](https://pytorch-geometric.readthedocs.io/en/stable/generated/torch_geometric.data.Data.html) structure containing the [`SelectOutput`](https://torch-geometric-pool.readthedocs.io/en/latest/api/select.html#tgp.select.SelectOutput) and the pooled connectivity matrix. \n",
    "Since we are using [`NDPPooling`](https://torch-geometric-pool.readthedocs.io/en/latest/api/poolers.html#tgp.poolers.NDPPooling), which internally calls [`NDPSelect`](https://torch-geometric-pool.readthedocs.io/en/latest/api/select.html#tgp.select.NDPSelect), we get an extra argument `L` representing the Laplacian matrix used by [`KronConnect`](https://torch-geometric-pool.readthedocs.io/en/latest/api/connect.html#tgp.connect.KronConnect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edc2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pooled_data in data.pooled_data:\n",
    "    print(pooled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244b071",
   "metadata": {},
   "source": [
    "This new Data strcture is very convenient as it carries all the information that the GNN needs to perform pooling at each coarsening level.\n",
    "With it, we do not need to keep track manually of the association between data samples and their pooled graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e830c2",
   "metadata": {},
   "source": [
    "## The PoolDataLoader\n",
    "\n",
    "The field `pooled_data` in these custom Data structures is *not* handled properly by the standard [`DataLoader`](https://pytorch-geometric.readthedocs.io/en/2.5.2/modules/loader.html#torch_geometric.loader.DataLoader) of <img src=\"https://raw.githubusercontent.com/TorchSpatiotemporal/tsl/main/docs/source/_static/img/logos/pyg.svg\" width=\"20px\" align=\"center\"/> PyG.\n",
    "While the node features, `x`, the edge indices, edge attributes, etc... are batched correctly, the pooled graphs are just concatenated in a list rather than being combined into a single batched graph for each pooling level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "pyg_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "next_batch = next(iter(pyg_loader))\n",
    "print(next_batch)\n",
    "print(next_batch.pooled_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7532bcb",
   "metadata": {},
   "source": [
    "To obtain well-formed batches with precomputed pooled graphs <img src=\"../_static/img/tgp-logo.svg\" width=\"20px\" align=\"center\" style=\"display: inline-block; height: 1.3em; width: unset; vertical-align: text-top;\"/> tgp provides the [`PoolDataLoader`](https://torch-geometric-pool.readthedocs.io/en/latest/api/data/loaders.html#tgp.data.loaders.PoolDataLoader).\n",
    "Now, the field `pooled_data` in the batch is a list containing a single batched graph for each coarsening level (2 in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgp.data import PoolDataLoader\n",
    "\n",
    "tgp_loader = PoolDataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "next_batch = next(iter(tgp_loader))\n",
    "print(next_batch)\n",
    "print(next_batch.pooled_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c2b12",
   "metadata": {},
   "source": [
    "A complete example of usage can be found [here](https://github.com/tgp-team/torch-geometric-pool/blob/main/examples/pre_coarsening.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-usage-header",
   "metadata": {},
   "source": [
    "## Advanced usage: multiple poolers and different configs per level\n",
    "\n",
    "You can build a **hierarchical network** with **more than one pooler** and **different poolers or configs at each level**. Pass a list of level specs to `PreCoarsening(poolers=...)`: each element is either a string alias (e.g. `\"ndp\"`, `\"graclus\"`) or a tuple `(alias, kwargs)` for that level.\n",
    "\n",
    "Examples:\n",
    "- Same pooler, same config: `[\"ndp\", \"ndp\"]`\n",
    "- Same pooler, different config: `[(\"nmf\", {\"k\": 8}), (\"nmf\", {\"k\": 4})]`\n",
    "- Mixed poolers: `[\"ndp\", (\"eigen\", {\"k\": 4, \"num_modes\": 3})]`\n",
    "\n",
    "In the model, use a `ModuleList` of reducers from `pre_transform.poolers`, one conv per level (accounting for `num_modes` for EigenPooling), and in `forward` loop over `data.pooled_data` and call `reducer(x=x, so=pooled.so)` then the next conv. Below is a full runnable example (mixed poolers: NDP then Eigen). For more schedules and a standalone script, see [pre_coarsening.py](https://github.com/tgp-team/torch-geometric-pool/blob/main/examples/pre_coarsening.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-usage-snippet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full runnable example: mixed poolers (NDP -> Eigen), 2 levels\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.nn import ARMAConv\n",
    "from tgp.data import PreCoarsening, PoolDataLoader\n",
    "from tgp.reduce import readout\n",
    "\n",
    "level_specs = [\"ndp\", (\"eigen\", {\"k\": 4, \"num_modes\": 3})]\n",
    "pre_transform_adv = PreCoarsening(poolers=level_specs)\n",
    "level_poolers = pre_transform_adv.poolers\n",
    "num_levels = len(level_poolers)\n",
    "\n",
    "dataset_adv = TUDataset(\n",
    "    root=\"/tmp/MUTAG_ndp_eigen\",\n",
    "    name=\"MUTAG\",\n",
    "    pre_transform=pre_transform_adv,\n",
    "    force_reload=True,\n",
    ")\n",
    "train_loader_adv = PoolDataLoader(dataset_adv[:150], batch_size=32, shuffle=True)\n",
    "test_loader_adv = PoolDataLoader(dataset_adv[150:], batch_size=32)\n",
    "\n",
    "level_num_modes = [getattr(p, \"num_modes\", 1) for p in level_poolers]\n",
    "\n",
    "\n",
    "class PrecoarsenedNet(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = ARMAConv(\n",
    "            dataset_adv.num_features, hidden_channels, num_layers=2\n",
    "        )\n",
    "        self.reducers = torch.nn.ModuleList([p.reducer for p in level_poolers])\n",
    "        self.next_conv = torch.nn.ModuleList()\n",
    "        for num_modes in level_num_modes:\n",
    "            in_ch = hidden_channels * num_modes\n",
    "            self.next_conv.append(\n",
    "                ARMAConv(in_ch, hidden_channels, num_layers=2)\n",
    "            )\n",
    "        self.lin = torch.nn.Linear(hidden_channels, dataset_adv.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.conv1(data.x, data.edge_index, data.edge_weight)\n",
    "        x = F.relu(x)\n",
    "        for pooled, conv, reducer in zip(data.pooled_data, self.next_conv, self.reducers):\n",
    "            x, _ = reducer(x=x, so=pooled.so)\n",
    "            x = conv(x, pooled.edge_index, pooled.edge_weight)\n",
    "            x = F.relu(x)\n",
    "        x = readout(x, reduce_op=\"sum\", batch=pooled.batch)\n",
    "        return F.log_softmax(self.lin(x), dim=-1)\n",
    "\n",
    "\n",
    "device_adv = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_adv = PrecoarsenedNet(hidden_channels=64).to(device_adv)\n",
    "optimizer_adv = torch.optim.Adam(model_adv.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "def train_adv():\n",
    "    model_adv.train()\n",
    "    total = 0\n",
    "    for data in train_loader_adv:\n",
    "        data = data.to(device_adv)\n",
    "        optimizer_adv.zero_grad()\n",
    "        loss = F.nll_loss(model_adv(data), data.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer_adv.step()\n",
    "        total += data.y.size(0) * float(loss)\n",
    "    return total / len(dataset_adv)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_adv(loader):\n",
    "    model_adv.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device_adv)\n",
    "        correct += int(model_adv(data).argmax(dim=-1).eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    loss = train_adv()\n",
    "    acc = test_adv(test_loader_adv)\n",
    "    print(f\"Epoch {epoch:2d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}\")\n",
    "print(f\"Final test accuracy: {test_adv(test_loader_adv):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37df078",
   "metadata": {},
   "source": [
    "## Other data transforms\n",
    "\n",
    "Some pooling layers come with custom transforms that should be applied to the data before starting to train the GNN.\n",
    "For example, [`JustBalancePooling`](https://torch-geometric-pool.readthedocs.io/en/latest/api/poolers.html#tgp.poolers.JustBalancePooling) transforms the connectivity matrix $\\mathbf{A}$ as follows:\n",
    "\n",
    "$$\\mathbf{A} \\to \\mathbf{I} - \\delta \\mathbf{L}$$\n",
    "\n",
    "The transforms associated with a given pooling operator are stored in the field `data_transforms()`. \n",
    "They can be accessed and passed to the dataset as any other <img src=\"https://raw.githubusercontent.com/TorchSpatiotemporal/tsl/main/docs/source/_static/img/logos/pyg.svg\" width=\"20px\" align=\"center\"/> PyG [`transform`](https://pytorch-geometric.readthedocs.io/en/2.5.2/modules/transforms.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgp.poolers import JustBalancePooling\n",
    "\n",
    "pooler = JustBalancePooling(in_channels=dataset.num_features, k=10)\n",
    "print(pooler.data_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46781a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(\n",
    "    root=\"/tmp/MUTAG\",\n",
    "    name=\"MUTAG\",\n",
    "    force_reload=True,\n",
    "    pre_transform=pooler.data_transforms(),  # transform specific for the pooler\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
